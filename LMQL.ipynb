{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32e378de-974f-4740-bf9f-f817fa99d94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lmql\n",
    "import asyncio\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('./env.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6892404c-b339-4845-be72-d00e6fc69071",
   "metadata": {},
   "source": [
    "# Simple token constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "918c2f16-c3e6-42ac-bdb0-519c5a5e17d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lmql.query\n",
    "async def tipo_test():\n",
    "    '''lmql\n",
    "    argmax\n",
    "        \"Pregunta: Sevilla es una ciudad ubicada en que parte de Espana \\n\"\n",
    "        \"A) Sur \\n\"\n",
    "        \"B) Norte \\n\"\n",
    "        \"C) Este \\n\"\n",
    "        \"D) Afuera de Espana \\n\"\n",
    "        \"Respuesta: [RESPUESTA]\"\n",
    "    from\n",
    "        \"openai/text-davinci-003\"\n",
    "    where\n",
    "        RESPUESTA in set([\"A\", \"B\", \"C\", \"D\"])\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7692251-9a00-4ae3-8a3f-d75472c3b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = await tipo_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80b024e9-3eac-4056-9db9-61a1fadd5a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LMQLResult(prompt='Pregunta: Sevilla es una ciudad ubicada en que parte de Espana \\nA) Sur \\nB) Norte \\nC) Este \\nD) Afuera de Espana \\nRespuesta: A', variables={'RESPUESTA': 'A'}, distribution_variable=None, distribution_values=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ae22464-6471-4101-bfce-bf55b2a16390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RESPUESTA': 'A'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[0].variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9c1e27-61a6-4844-8133-07550138c8fa",
   "metadata": {},
   "source": [
    "# Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73b82df9-ff42-4562-99b1-1388a7686c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este parece no funcionar bien con OpenAI api\n",
    "\n",
    "@lmql.query\n",
    "async def sentiment_analysis(input):\n",
    "    '''lmql\n",
    "    argmax\n",
    "        \"Classifica el sentimiento de la siguiente frase como POS, NEG O NEUT: \\n\"\n",
    "        \"{input} \\n\"\n",
    "        \"El sentimento de la frase es [SENTIMENT]\"\n",
    "    from\n",
    "        \"openai/text-davinci-003\"\n",
    "    distribution\n",
    "        SENTIMENT in [\"POS\", \"NEUT\", \"NEG\"]\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a95768eb-396a-47a1-b2dd-c3364b6b51a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/lmql/runtime/openai_integration.py:248: UserWarning: warning: The OpenAI API has merged 1 token(s) server-side, which will reflect in inaccurate 0.0 scores in the decoding tree\n",
      "  warnings.warn(\"warning: The OpenAI API has merged {} token(s) server-side, which will reflect in inaccurate 0.0 scores in the decoding tree\".format(server_side_swallowed_tokens))\n"
     ]
    }
   ],
   "source": [
    "r = await sentiment_analysis('Estoy muy feliz hoy!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6664e56e-cbec-4ae8-b51b-6aa6ddd97b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['SENTIMENT', 'P(SENTIMENT)', 'log P(SENTIMENT)'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.variables.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06690939-da34-4d3e-a70c-94828a41a6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('POS', 0.3336377781463958),\n",
       " ('NEUT', 0.33275176110373544),\n",
       " ('NEG', 0.33361046074986866)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.variables.get('P(SENTIMENT)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769b8103-b14d-42f2-9315-1c95db76958b",
   "metadata": {},
   "source": [
    "# JSON response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d65e7bf-15e5-46a2-82ad-53b5c40f60d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f478fdc6-974a-4c05-9227-c2f93da61d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only works in playground :p ?? \n",
    "# This only works if install directly from github, not pip (ie pip install git+https://github.com/eth-sri/lmql)\n",
    "\n",
    "\n",
    "@lmql.query\n",
    "async def jsonize():\n",
    "    '''lmql\n",
    "        from dataclasses import dataclass\n",
    "        import lmql\n",
    "        \n",
    "        @dataclass\n",
    "        class Event:\n",
    "            nombre: str\n",
    "            descripcion: str\n",
    "                \n",
    "        @dataclass\n",
    "        class Meetup:\n",
    "            nombre: str\n",
    "            organizadores: str\n",
    "            event: Event\n",
    "    \n",
    "        argmax\n",
    "            \"\"\"\n",
    "            Por favor, coloca el texto a continuación en un formato JSON estructurado:\n",
    "            IA Generativa Sevilla es un grupo de meetup colocada en Sevilla, Espana. Los organizadores son Ivan y Mathias\n",
    "            El evento de hoy trata de dominando un LLM utilizando LMQL\n",
    "            structured: [MEETUP]\n",
    "            \"\"\"\n",
    "        from\n",
    "            \"openai/text-davinci-003\"\n",
    "        where\n",
    "            type(MEETUP) is Meetup\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5588ec17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LMQLResult(prompt=\"\\nPor favor, coloca el texto a continuación en un formato JSON estructurado:\\nIA Generativa Sevilla es un grupo de meetup colocada en Sevilla, Espana. Los organizadores son Ivan y Mathias\\nEl evento de hoy trata de dominando un LLM utilizando LMQL\\nstructured: Meetup(nombre='IA Generativa Sevilla', organizadores='Ivan y Mathias', event=Event(nombre='Dominando un LLM utilizando LMQL', descripcion='Un grupo de meetup en Sevilla, España'))\\n\", variables={'MEETUP': Meetup(nombre='IA Generativa Sevilla', organizadores='Ivan y Mathias', event=Event(nombre='Dominando un LLM utilizando LMQL', descripcion='Un grupo de meetup en Sevilla, España'))}, distribution_variable=None, distribution_values=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = await jsonize()\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d459fb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Meetup(nombre='IA Generativa Sevilla', organizadores='Ivan y Mathias', event=Event(nombre='Dominando un LLM utilizando LMQL', descripcion='Un grupo de meetup en Sevilla, España'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.variables['MEETUP']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a859ae6",
   "metadata": {},
   "source": [
    "# Create json without dataclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ed37483-7d2c-439c-801e-fc16224f73a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lmql.query\n",
    "async def jsonize():\n",
    "    '''lmql\n",
    "    argmax \n",
    "        \"\"\"\n",
    "        Por favor, coloca el texto a continuación en un formato JSON estructurado:\n",
    "\n",
    "        IA Generativa Sevilla es un grupo de meetup colocada en Sevilla, Espana. Los organizadores son Ivan y Mathias\n",
    "        El evento de hoy trata de dominando un LLM utilizando LMQL\n",
    "\n",
    "        {{\n",
    "        \"meetup-name\": \"[NAME]\",\n",
    "        \"location\": \"[LOCATION]\",\n",
    "        \"organizers\": \"[ORGANIZERS]\",\n",
    "        \"description\": \"[DESCRIPTION]\",\n",
    "        }}\n",
    "        \"\"\"\n",
    "    from\n",
    "        \"openai/text-davinci-003\" \n",
    "    where\n",
    "        STOPS_BEFORE(NAME, '\"') and STOPS_BEFORE(DESCRIPTION, '\"') and STOPS_BEFORE(LOCATION, '\"') and STOPS_BEFORE(ORGANIZERS, '\"') and len(NAME) < 25\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a73c3478",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/lmql/runtime/bopenai/batched_openai.py:741: OpenAILogitBiasLimitationWarning: the required logit_bias is too large to be handled by the OpenAI API and will be limited to the first 300 tokens. This can lead to the violation of the provided constraints or undesired model output. To avoid this use less broad or no constraints.\n",
      "  warnings.warn(\"the required logit_bias is too large to be handled by the OpenAI API and will be limited to the first 300 tokens. This can lead to the violation of the provided constraints or undesired model output. To avoid this use less broad or no constraints.\", category=OpenAILogitBiasLimitationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LMQLResult(prompt='\\nPor favor, coloca el texto a continuación en un formato JSON estructurado:\\nIA Generativa Sevilla es un grupo de meetup colocada en Sevilla, Espana. Los organizadores son Ivan y Mathias\\nEl evento de hoy trata de dominando un LLM utilizando LMQL\\n{\\n\"meetup-name\": \"IA Generativa Sevilla\",\\n\"location\": \"Sevilla, Espana\",\\n\"organizers\": \"Ivan y Mathias\",\\n\"description\": \"Dominando un LLM utilizando LMQL\",\\n}\\n', variables={'NAME': 'IA Generativa Sevilla', 'LOCATION': 'Sevilla, Espana', 'ORGANIZERS': 'Ivan y Mathias', 'DESCRIPTION': 'Dominando un LLM utilizando LMQL'}, distribution_variable=None, distribution_values=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = await jsonize()\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c98c3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NAME': 'IA Generativa Sevilla',\n",
       " 'LOCATION': 'Sevilla, Espana',\n",
       " 'ORGANIZERS': 'Ivan y Mathias',\n",
       " 'DESCRIPTION': 'Dominando un LLM utilizando LMQL'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[0].variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff68d415",
   "metadata": {},
   "source": [
    "# Calling function / control flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88691af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f217dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://api.dictionaryapi.dev/api/v2/entries/en/{word}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2620d943",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_definitions(word):\n",
    "    data = requests.get(url.format(word=word)).json()\n",
    "    # Extract the definitions\n",
    "    definitions = []\n",
    "    for meaning in data[0]['meanings'][0]['definitions']:\n",
    "        definitions.append(f\"definition: {meaning['definition']}\")\n",
    "    return definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98b1f28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lmql.query\n",
    "async def example_sentence(term):\n",
    "    '''lmql\n",
    "    argmax\n",
    "        \"\"\"\n",
    "        Please provide an example sentences for each definition of the word: {term}\n",
    "        \"\"\"\n",
    "\n",
    "        definitions = await get_definitions(term)\n",
    "        definition_strings = \"\\n\".join(definitions)\n",
    "\n",
    "        \"\"\"\n",
    "        Here are the dictionary definitions:\n",
    "        {definition_strings}\n",
    "        \"\"\"\n",
    "        \n",
    "        examples = []\n",
    "        for i in range(len(definitions)):\n",
    "            \"-[EXAMPLE]\" where STOPS_AT(EXAMPLE, \"\\n\")\n",
    "            examples.append(EXAMPLE.strip())\n",
    "        return examples\n",
    "    from\n",
    "        \"openai/text-davinci-003\"\n",
    "    '''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b874fda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await example_sentence(\"Asynchronous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97ef4ba1-6d2f-4613-b498-43e49414c3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Example sentence 1: The asynchronous nature of the internet allows for multiple users to access the same website simultaneously.',\n",
       " 'Example sentence 2: The asynchronous request allowed the client to continue browsing while the server processed the data.',\n",
       " 'Example sentence 3: The asynchronous communication between the two computers allowed for multiple actions to occur at the same time.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d3dd6d-4a18-4e0f-b19c-6ab719593477",
   "metadata": {},
   "source": [
    "# Open Source Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7459a23-0452-4ecf-bd82-63ded97c2665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hay que crear un server local:\n",
    "# https://docs.lmql.ai/en/stable/language/hf.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ef9174c1-e327-4825-8237-146adf9ed631",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lmql.query\n",
    "async def example_os_model_sql(pregunta):\n",
    "        '''lmql\n",
    "        argmax \n",
    "            \"\"\"\n",
    "            Dada la tabla a continuación, por favor responda la pregunta a continuación con una consulta SQL válida.\n",
    "            Por favor, utilice solamente la tabla que se encuentra a continuación:\n",
    "\n",
    "            ### Tablas:\n",
    "            CREATE TABLE transactions (\n",
    "                transaction_id INT PRIMARY KEY AUTO_INCREMENT,\n",
    "                customer_id INT NOT NULL,\n",
    "                product_id INT NOT NULL,\n",
    "                transaction_date DATE NOT NULL,\n",
    "                amount DECIMAL(10, 2) NOT NULL,\n",
    "                payment_method VARCHAR(50) NOT NULL,\n",
    "                transaction_status VARCHAR(20) NOT NULL,\n",
    "                FOREIGN KEY (customer_id) REFERENCES customers(customer_id),\n",
    "                FOREIGN KEY (product_id) REFERENCES products(product_id)\n",
    "            );\n",
    "    \n",
    "            Q: {pregunta}\n",
    "            A: SELECT [QUERY]\n",
    "            \"\"\"\n",
    "        from\n",
    "            lmql.model(\"meta-llama/Llama-2-7b-chat-hf\", endpoint=\"localhost:9999\", tokenizer='hf-internal-testing/llama-tokenizer', device=0)\n",
    "        where\n",
    "            STOPS_BEFORE(QUERY, ';')\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9f293a7c-5338-4a5d-81fa-9990695aa6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = await example_os_model_sql(pregunta=\"Por favor, proporciona las últimas cinco transacciones.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "55c15423-d761-42b1-9f5b-f30693b78c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT\n",
      "    *\n",
      "FROM \n",
      "    transactions\n",
      "\n",
      "ORDER BY \n",
      "    transaction_date DESC\n",
      "\n",
      "LIMIT 5\n"
     ]
    }
   ],
   "source": [
    "print('SELECT' + resp.variables.get('QUERY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b68204-0841-461d-abc4-76c81b00e5b4",
   "metadata": {},
   "source": [
    "# Distribucion con open source model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4ddbd86d-4e68-4511-ae22-0f11fa20c161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este parece no funcionar bien con OpenAI api\n",
    "\n",
    "@lmql.query\n",
    "async def sentiment_analysis(input):\n",
    "    '''lmql\n",
    "    argmax\n",
    "        \"Classifica el sentimiento de la siguiente frase como positivo, negativo o neutral: \\n\"\n",
    "        \"###Frase \\n\"\n",
    "        \"{input} \\n\"\n",
    "        \"Pensamiento: [REASONING] \\n\"\n",
    "        \"Por eso creo que el sentimento de la frase es [SENTIMENT]\"\n",
    "    from\n",
    "        lmql.model(\"meta-llama/Llama-2-7b-chat-hf\", endpoint=\"localhost:9999\", tokenizer='hf-internal-testing/llama-tokenizer', device=0)\n",
    "    distribution\n",
    "        SENTIMENT in [\"POS\", \"NEUT\", \"NEG\"]\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "64a2296b-3b98-4cbe-bbb7-cb12805e2542",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = await sentiment_analysis('Estoy muy feliz hoy!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8984f2ba-3339-4a36-afb6-b46e5a8c47c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'REASONING': '\\nLa frase \"Estoy muy feliz hoy\" es una expresión positiva, ya que el término \"feliz\" tiene un significado que se refiere a un estado de ánimo alegre y satisfactorio. Por lo tanto, la frase se clasifica como positiva.',\n",
       " 'SENTIMENT': 'POS',\n",
       " 'P(SENTIMENT)': [('POS', 0.8116896641444746),\n",
       "  ('NEUT', 0.15510277328034572),\n",
       "  ('NEG', 0.03320756257517929)],\n",
       " 'log P(SENTIMENT)': [('POS', -0.2086371988867235),\n",
       "  ('NEUT', -1.8636673283641052),\n",
       "  ('NEG', -3.40497764059052)]}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.variables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
