{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32e378de-974f-4740-bf9f-f817fa99d94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lmql\n",
    "import asyncio\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6892404c-b339-4845-be72-d00e6fc69071",
   "metadata": {},
   "source": [
    "# Simple token constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "918c2f16-c3e6-42ac-bdb0-519c5a5e17d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lmql.query\n",
    "async def tipo_test():\n",
    "    '''lmql\n",
    "    argmax\n",
    "        \"Pregunta: Sevilla es una ciudad ubicada en que parte de Espana \\n\"\n",
    "        \"A) Sur \\n\"\n",
    "        \"B) Norte \\n\"\n",
    "        \"C) Este \\n\"\n",
    "        \"D) Afuera de Espana \\n\"\n",
    "        \"Respuesta: [RESPUESTA]\"\n",
    "    from\n",
    "        \"openai/text-davinci-003\"\n",
    "    where\n",
    "        RESPUESTA in set([\"A\", \"B\", \"C\", \"D\"])\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7692251-9a00-4ae3-8a3f-d75472c3b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = await tipo_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80b024e9-3eac-4056-9db9-61a1fadd5a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LMQLResult(prompt='Pregunta: Sevilla es una ciudad ubicada en que parte de Espana \\nA) Sur \\nB) Norte \\nC) Este \\nD) Afuera de Espana \\nRespuesta: A', variables={'RESPUESTA': 'A'}, distribution_variable=None, distribution_values=None)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ae22464-6471-4101-bfce-bf55b2a16390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RESPUESTA': 'A'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[0].variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9c1e27-61a6-4844-8133-07550138c8fa",
   "metadata": {},
   "source": [
    "# Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73b82df9-ff42-4562-99b1-1388a7686c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lmql.query\n",
    "async def sentiment_analysis(input):\n",
    "    '''lmql\n",
    "    argmax\n",
    "        \"Classifica el sentimiento de la siguiente frase como POS, NEG O NEUT: \\n\"\n",
    "        \"{input} \\n\"\n",
    "        \"El sentimento de la frase es [SENTIMENT]\"\n",
    "    from\n",
    "        \"openai/text-davinci-003\"\n",
    "    distribution\n",
    "        SENTIMENT in [\"POS\", \"NEUT\", \"NEG\"]\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a95768eb-396a-47a1-b2dd-c3364b6b51a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mathiashaugestad/opt/anaconda3/envs/semantic-kernel/lib/python3.11/site-packages/lmql/runtime/caching.py:33: UserWarning: LMQL cache directory (/Users/mathiashaugestad/.cache/lmql) format is outdated, clearing cache (existing: v3, runtime: v5)...\n",
      "  warnings.warn(\"LMQL cache directory ({}) format is outdated, clearing cache (existing: v{}, runtime: v{})...\".format(CACHE_DIR, cache_version, CACHE_VERSION))\n",
      "/Users/mathiashaugestad/opt/anaconda3/envs/semantic-kernel/lib/python3.11/site-packages/lmql/runtime/openai_integration.py:237: UserWarning: warning: The OpenAI API has merged 1 token(s) server-side, which will reflect in inaccurate 0.0 scores in the decoding tree\n",
      "  warnings.warn(\"warning: The OpenAI API has merged {} token(s) server-side, which will reflect in inaccurate 0.0 scores in the decoding tree\".format(server_side_swallowed_tokens))\n"
     ]
    }
   ],
   "source": [
    "r = await sentiment_analysis('Estoy muy feliz hoy!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6664e56e-cbec-4ae8-b51b-6aa6ddd97b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['SENTIMENT', 'P(SENTIMENT)', 'log P(SENTIMENT)'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.variables.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06690939-da34-4d3e-a70c-94828a41a6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('POS', 0.3336381603931782),\n",
       " ('NEUT', 0.33275111579463185),\n",
       " ('NEG', 0.33361072381218987)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.variables.get('P(SENTIMENT)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769b8103-b14d-42f2-9315-1c95db76958b",
   "metadata": {},
   "source": [
    "# JSON response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d65e7bf-15e5-46a2-82ad-53b5c40f60d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f478fdc6-974a-4c05-9227-c2f93da61d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only works in playground :p ?? \n",
    "# This only works if install directly from github, not pip (ie pip install git+https://github.com/eth-sri/lmql)\n",
    "\n",
    "\n",
    "@lmql.query\n",
    "async def jsonize():\n",
    "    '''lmql\n",
    "        from dataclasses import dataclass\n",
    "        import lmql\n",
    "        \n",
    "        @dataclass\n",
    "        class Event:\n",
    "            nombre: str\n",
    "            descripcion: str\n",
    "                \n",
    "        @dataclass\n",
    "        class Meetup:\n",
    "            nombre: str\n",
    "            organizadores: str\n",
    "            event: Event\n",
    "    \n",
    "        argmax\n",
    "            \"\"\"\n",
    "            Por favor, coloca el texto a continuaci贸n en un formato JSON estructurado:\n",
    "            IA Generativa Sevilla es un grupo de meetup colocada en Sevilla, Espana. Los organizadores son Ivan y Mathias\n",
    "            El evento de hoy trata de dominando un LLM utilizando LMQL\n",
    "            structured: [MEETUP]\n",
    "            \"\"\"\n",
    "        from\n",
    "            \"openai/text-davinci-003\"\n",
    "        where\n",
    "            type(MEETUP) is Meetup\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5588ec17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LMQLResult(prompt=\"\\nPor favor, coloca el texto a continuaci贸n en un formato JSON estructurado:\\nIA Generativa Sevilla es un grupo de meetup colocada en Sevilla, Espana. Los organizadores son Ivan y Mathias\\nEl evento de hoy trata de dominando un LLM utilizando LMQL\\nstructured: Meetup(nombre='IA Generativa Sevilla', organizadores='Ivan y Mathias', event=Event(nombre='Dominando un LLM utilizando LMQL', descripcion='Un grupo de meetup en Sevilla, Espana'))\\n\", variables={'MEETUP': Meetup(nombre='IA Generativa Sevilla', organizadores='Ivan y Mathias', event=Event(nombre='Dominando un LLM utilizando LMQL', descripcion='Un grupo de meetup en Sevilla, Espana'))}, distribution_variable=None, distribution_values=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = await jsonize()\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d459fb12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Meetup(nombre='IA Generativa Sevilla', organizadores='Ivan y Mathias', event=Event(nombre='Dominando un LLM utilizando LMQL', descripcion='Un grupo de meetup en Sevilla, Espana'))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.variables['MEETUP']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a859ae6",
   "metadata": {},
   "source": [
    "# Create json without dataclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ed37483-7d2c-439c-801e-fc16224f73a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lmql.query\n",
    "async def jsonize():\n",
    "    '''lmql\n",
    "    argmax \n",
    "        \"\"\"\n",
    "        Por favor, coloca el texto a continuaci贸n en un formato JSON estructurado:\n",
    "\n",
    "        IA Generativa Sevilla es un grupo de meetup colocada en Sevilla, Espana. Los organizadores son Ivan y Mathias\n",
    "        El evento de hoy trata de dominando un LLM utilizando LMQL\n",
    "\n",
    "        {{\n",
    "        \"meetup-name\": \"[NAME]\",\n",
    "        \"location\": \"[LOCATION]\",\n",
    "        \"organizers\": \"[ORGANIZERS]\",\n",
    "        \"description\": \"[DESCRIPTION]\",\n",
    "        }}\n",
    "        \"\"\"\n",
    "    from\n",
    "        \"openai/text-davinci-003\" \n",
    "    where\n",
    "        STOPS_BEFORE(NAME, '\"') and STOPS_BEFORE(DESCRIPTION, '\"') and STOPS_BEFORE(LOCATION, '\"') and STOPS_BEFORE(ORGANIZERS, '\"') and len(NAME) < 25\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a73c3478",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mathiashaugestad/opt/anaconda3/envs/semantic-kernel/lib/python3.11/site-packages/lmql/runtime/bopenai/batched_openai.py:741: OpenAILogitBiasLimitationWarning: the required logit_bias is too large to be handled by the OpenAI API and will be limited to the first 300 tokens. This can lead to the violation of the provided constraints or undesired model output. To avoid this use less broad or no constraints.\n",
      "  warnings.warn(\"the required logit_bias is too large to be handled by the OpenAI API and will be limited to the first 300 tokens. This can lead to the violation of the provided constraints or undesired model output. To avoid this use less broad or no constraints.\", category=OpenAILogitBiasLimitationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LMQLResult(prompt='\\nPor favor, coloca el texto a continuaci贸n en un formato JSON estructurado:\\nIA Generativa Sevilla es un grupo de meetup colocada en Sevilla, Espana. Los organizadores son Ivan y Mathias\\nEl evento de hoy trata de dominando un LLM utilizando LMQL\\n{\\n\"meetup-name\": \"IA Generativa Sevilla\",\\n\"location\": \"Sevilla, Espana\",\\n\"organizers\": \"Ivan y Mathias\",\\n\"description\": \"Dominando un LLM utilizando LMQL\",\\n}\\n', variables={'NAME': 'IA Generativa Sevilla', 'LOCATION': 'Sevilla, Espana', 'ORGANIZERS': 'Ivan y Mathias', 'DESCRIPTION': 'Dominando un LLM utilizando LMQL'}, distribution_variable=None, distribution_values=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = await jsonize()\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c98c3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NAME': 'IA Generativa Sevilla',\n",
       " 'LOCATION': 'Sevilla, Espana',\n",
       " 'ORGANIZERS': 'Ivan y Mathias',\n",
       " 'DESCRIPTION': 'Dominando un LLM utilizando LMQL'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[0].variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff68d415",
   "metadata": {},
   "source": [
    "# Calling function / control flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "88691af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f217dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://api.dictionaryapi.dev/api/v2/entries/en/{word}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2620d943",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_definitions(word):\n",
    "    data = requests.get(url.format(word='asynchronous')).json()\n",
    "    # Extract the definitions\n",
    "    definitions = []\n",
    "    for meaning in data[0]['meanings'][0]['definitions']:\n",
    "        definitions.append(f\"definition: {meaning['definition']}\")\n",
    "    return definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "98b1f28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lmql.query\n",
    "async def example_sentence(term):\n",
    "    '''lmql\n",
    "    argmax\n",
    "        \"\"\"\n",
    "        Please provide an example sentences for each definition of the word: {term}\n",
    "        \"\"\"\n",
    "\n",
    "        definitions = await get_definitions(term)\n",
    "        definition_strings = \"\\n\".join(definitions)\n",
    "\n",
    "        \"\"\"\n",
    "        Here are the dictionary definitions:\n",
    "        {definition_strings}\n",
    "        \"\"\"\n",
    "        \n",
    "        examples = []\n",
    "        for i in range(len(definitions)):\n",
    "            \"-[EXAMPLE]\" where STOPS_AT(EXAMPLE, \"\\n\")\n",
    "            examples.append(EXAMPLE.strip())\n",
    "    from\n",
    "        \"openai/text-davinci-003\"\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b874fda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await example_sentence(\"Asynchronous\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
